{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP analysis of some of the past President's acceptance speech as the Democratic/Republican presidential candidate.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- **[John F. Kennedy 1960](https://www.jfklibrary.org/learn/about-jfk/historic-speeches/acceptance-of-democratic-nomination-for-president)**\n",
    "- **[Ronald Reagan 1980](https://www.c-span.org/video/?c4609012/ronald-reagan-1980-republican-party-nomination-acceptance-speech)**\n",
    "- **[George H.W. Bush 1988](https://www.c-span.org/video/?3848-1/george-hw-bush-1988-acceptance-speech)**\n",
    "- **[Barack Obama 2008](https://www.npr.org/templates/story/story.php?storyId=94087570)**\n",
    "\n",
    "\n",
    "### We do some feature engineering, sentient analysis and try to predict which president would have said a specific sentence. At this time the best accuracy is about 60%. \n",
    "\n",
    "\n",
    "`NLP`\n",
    "`NLTK`\n",
    "`gridsearchCV`\n",
    "`RandomForest`\n",
    "`GradientBoost`\n",
    "\n",
    "\n",
    "***\n",
    "Developed by __M.Safaei [L i n k e d i n](https://www.linkedin.com/in/mattsafaei/)__\n",
    "\n",
    "***\n",
    "__an ongoing project...__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Kennedy = open(\"Kennedy.txt\").read()\n",
    "data_Raegan = open(\"Raegan.txt\").read()\n",
    "data_Bush = open(\"Bush.txt\").read()\n",
    "data_Obama = open(\"Obama.txt\").read()\n",
    "\n",
    "data_all = [data_Kennedy,data_Raegan,data_Bush,data_Obama]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences: 127\n",
      "number of sentences: 217\n",
      "number of sentences: 299\n",
      "number of sentences: 226\n"
     ]
    }
   ],
   "source": [
    "for i in data_all:\n",
    "    print('number of sentences: {}'.format(len(sent_tokenize(i))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **<font color=green>Green</font>** is overal positive compoundscore <font color=green>(positive statement)</font>\n",
    "- **<font color=red>Red</font>** is overal negative compound score  <font color=red>(negative statement)</font>\n",
    "- **<font color=gray>Gray</font>** is overal close to compound zero score <font color=gray>(neutral statement)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "#color code based on compound\n",
    "def map_colors(a_dict):\n",
    "    if a_dict['compound'] < 0 : return 41 # negative\n",
    "    if a_dict['compound'] >0 : return 42 # positive \n",
    "    return 47 # neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_print_text(input_file, polarity_list, numsents = 20):\n",
    "    myList = []\n",
    "    for i, sentence in enumerate(sent_tokenize(input_file)):\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        #\n",
    "        if ss['compound'] < 0:\n",
    "            polarity_list.append('Negative')\n",
    "            myList.append('Negative')\n",
    "        elif ss['compound'] > 0:\n",
    "            polarity_list.append('Positive')\n",
    "            myList.append('Positive')\n",
    "        else:\n",
    "            polarity_list.append('Neutral')\n",
    "            myList.append('Neutral')\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if i < numsents:\n",
    "                if myList[i] != myList[i-1]:\n",
    "                    print('\\033[' + str(map_colors(ss)) + 'm' + sentence + '\\033[0m')\n",
    "    return polarity_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kennedy's Acceptance Speech:\n",
    "\n",
    "> #### **<font color=green>Green:</font>** <font color=green>positive sentence</font>\n",
    "> #### **<font color=red>Red:</font>** <font color=red>negative sentence</font>\n",
    "> #### **<font color=gray>Gray:</font>** <font color=gray>neutral sentence</font>\n",
    "\n",
    "#### Print is limited to the first 20 sentences to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[47mPledges which are made so eloquently are made to be kept.\u001b[0m\n",
      "\u001b[42m\"The Rights of Man\"--the civil and economic rights essential to the human dignity of all men--are indeed our goal and our first principles.\u001b[0m\n",
      "\u001b[41mI hope that no American, considering the really critical issues facing this country, will waste his franchise by voting either for me or against me solely on account of my religious affiliation.\u001b[0m\n",
      "\u001b[47mIt is not relevant.\u001b[0m\n",
      "\u001b[41mI want to stress, what some other political or religious leader may have said on this subject.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "polarity_k = []\n",
    "polarity_print_text(data_Kennedy,polarity_k);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since colored Print is not Supported in GitHub, here is snapshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RF](./Kennedy.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raegan's speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[47mWe're using up prime time.\u001b[0m\n",
      "\u001b[42mThank you very much.\u001b[0m\n",
      "\u001b[47mYou're singing our song.\u001b[0m\n",
      "\u001b[42mWell, the first thrill tonight was to find myself for the first time in a long time in a movie on prime time.\u001b[0m\n",
      "\u001b[47mNow I know we've had a quarrel or two but only as to the method of attaining a goal.\u001b[0m\n",
      "\u001b[41mThere was no argument here about the goal.\u001b[0m\n",
      "\u001b[42mAs President, I will establish a liaison with the 50 Governors to encourage them to eliminate, wherever it exists, discrimination against women.\u001b[0m\n",
      "\u001b[47mI will monitor Federal laws to insure their implementation and to add statutes if they are needed.\u001b[0m\n",
      "\u001b[42mMore than anything else, I want my candidacy to unify our country, to renew the American spirit and sense of purpose.\u001b[0m\n",
      "\u001b[41mNever before in our history have Americans been called upon to face three grave threats to our very existence, any one of which could destroy us.\u001b[0m\n",
      "\u001b[42mWe face a disintegrating economy, a weakened defense and an energy policy based on the sharing of scarcity.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "polarity_r = []\n",
    "polarity_print_text(data_Raegan, polarity_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# George H.W. Bush's speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[47mMany of you have asked, \"When will this campaign really begin?\"\u001b[0m\n",
      "\u001b[41mFor seven and a half years I have helped a President conduct the most difficult job on earth.\u001b[0m\n",
      "\u001b[47mRonald Reagan asked for, and received, my candor.\u001b[0m\n",
      "\u001b[42mHe never asked for, but he did receive, my loyalty.\u001b[0m\n",
      "\u001b[47mAnd so tonight is for big things.\u001b[0m\n",
      "\u001b[42mBut I'll try to be fair to the other side.\u001b[0m\n",
      "\u001b[47mI'll try to hold my charisma in check.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "polarity_b = []\n",
    "polarity_print_text(data_Bush, polarity_b);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obama's speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[47mThat's why I stand here tonight.\u001b[0m\n",
      "\u001b[42mBecause for 232 years, at each moment when that promise was in jeopardy, ordinary men and women â€” students and soldiers, farmers and teachers, nurses and janitors â€” found the courage to keep it alive.\u001b[0m\n",
      "\u001b[41mWe meet at one of those defining moments â€” a moment when our nation is at war, our economy is in turmoil, and the American promise has been threatened once more.\u001b[0m\n",
      "\u001b[47mTonight, more Americans are out of work and more are working harder for less.\u001b[0m\n",
      "\u001b[42mMore of you have lost your homes and even more are watching your home values plummet.\u001b[0m\n",
      "\u001b[41mBut the failure to respond is a direct result of a broken politics in Washington and the failed policies of George W. Bush.\u001b[0m\n",
      "\u001b[42mAmerica, we are better than these last eight years.\u001b[0m\n",
      "\u001b[41mThis country is more decent than one where a woman in Ohio, on the brink of retirement, finds herself one illness away from disaster after a lifetime of hard work.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "polarity_o = []\n",
    "polarity_print_text(data_Obama, polarity_o);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, \"Obama's speech\")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_b = { x: polarity_b.count(x) for x in list(set(polarity_b))}\n",
    "d_k = { x: polarity_k.count(x) for x in list(set(polarity_k))}\n",
    "d_r = { x: polarity_r.count(x) for x in list(set(polarity_r))}\n",
    "d_o = { x: polarity_o.count(x) for x in list(set(polarity_o))}\n",
    "\n",
    "box = dict(facecolor='yellow', pad=5, alpha=0.2)\n",
    "\n",
    "dt = [d_b, d_k, d_r, d_o]\n",
    "        \n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(141)\n",
    "values = [d_b[i] for i in d_b]\n",
    "names = [i for i in d_b]\n",
    "plt.bar(tuple(names), tuple(values) ,color='Black')\n",
    "plt.ylim([0,140])\n",
    "plt.title('Bush\\'s speech',bbox=box)\n",
    "\n",
    "plt.subplot(143)\n",
    "values = [d_k[i] for i in d_k]\n",
    "names = [i for i in d_k]\n",
    "plt.bar(tuple(names), tuple(values) ,color='Red')\n",
    "plt.ylim([0,140])\n",
    "plt.title('Kennedy\\'s speech',bbox=box)\n",
    "\n",
    "plt.subplot(142)\n",
    "values = [d_r[i] for i in d_r]\n",
    "names = [i for i in d_r]\n",
    "plt.bar(tuple(names), tuple(values) ,color='Blue')\n",
    "plt.title('Raegan\\'s speech',bbox=box)\n",
    "plt.ylim([0,140])\n",
    "\n",
    "plt.subplot(144)\n",
    "values = [d_o[i] for i in d_o]\n",
    "names = [i for i in d_o]\n",
    "plt.bar(tuple(names), tuple(values) ,color='Black')\n",
    "plt.ylim([0,140])\n",
    "plt.title('Obama\\'s speech',bbox=box)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raegan's speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>Raegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We're using up prime time.</td>\n",
       "      <td>Raegan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>Raegan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Text  Person\n",
       "0        Thank you very much.  Raegan\n",
       "1  We're using up prime time.  Raegan\n",
       "2        Thank you very much.  Raegan"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame_Raegan = pd.DataFrame({\n",
    "    'Text': sent_tokenize(data_Raegan)\n",
    "            })\n",
    "DataFrame_Raegan['Person']=  'Raegan'\n",
    "DataFrame_Raegan.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kennedy's speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Governor Stevenson, Senator Johnson,...</td>\n",
       "      <td>Kennedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was my great honor to place his n...</td>\n",
       "      <td>Kennedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With a deep sense of duty and high r...</td>\n",
       "      <td>Kennedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text   Person\n",
       "0  Governor Stevenson, Senator Johnson,...  Kennedy\n",
       "1  It was my great honor to place his n...  Kennedy\n",
       "2  With a deep sense of duty and high r...  Kennedy"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame_Kennedy = pd.DataFrame({\n",
    "    'Text': sent_tokenize(data_Kennedy)\n",
    "                })\n",
    "DataFrame_Kennedy['Person']=  'Kennedy'\n",
    "DataFrame_Kennedy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bush's speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have many friends to thank tonight.</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I thank the voters who supported me.</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thank the gallant men who entered ...</td>\n",
       "      <td>Bush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Person\n",
       "0    I have many friends to thank tonight.   Bush\n",
       "1     I thank the voters who supported me.   Bush\n",
       "2  I thank the gallant men who entered ...   Bush"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame_Bush = pd.DataFrame({\n",
    "    'Text': sent_tokenize(data_Bush)\n",
    "                })\n",
    "DataFrame_Bush['Person']=  'Bush'\n",
    "DataFrame_Bush.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obama's speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To Chairman Dean and my great friend...</td>\n",
       "      <td>Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let me express my thanks to the hist...</td>\n",
       "      <td>Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To President Clinton, who last night...</td>\n",
       "      <td>Obama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Person\n",
       "0  To Chairman Dean and my great friend...  Obama\n",
       "1  Let me express my thanks to the hist...  Obama\n",
       "2  To President Clinton, who last night...  Obama"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame_Obama = pd.DataFrame({\n",
    "    'Text': sent_tokenize(data_Obama)\n",
    "                })\n",
    "DataFrame_Obama['Person']=  'Obama'\n",
    "DataFrame_Obama.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_stem(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_text_lemmatize(text):\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [wn.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame_Kennedy.drop('body_len', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pandas dataframe, tokenize, lemmatize and stemmize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stemmed_len</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>lemmatize_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Governor Stevenson, Senator Johnson,...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[governor, stevenson, senat, johnson...</td>\n",
       "      <td>23</td>\n",
       "      <td>[Governor, Stevenson, Senator, Johns...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was my great honor to place his n...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[It, great, honor, place, name, nomi...</td>\n",
       "      <td>17</td>\n",
       "      <td>[It, great, honor, place, name, nomi...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>With a deep sense of duty and high r...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[with, deep, sens, duti, high, resol...</td>\n",
       "      <td>9</td>\n",
       "      <td>[With, deep, sense, duty, high, reso...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I accept it with a full and grateful...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[I, accept, full, grate, heartwithou...</td>\n",
       "      <td>22</td>\n",
       "      <td>[I, accept, full, grateful, heartwit...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am grateful, too, that you have pr...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[I, grate, provid, eloqu, statement,...</td>\n",
       "      <td>7</td>\n",
       "      <td>[I, grateful, provided, eloquent, st...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text   Person  \\\n",
       "0  Governor Stevenson, Senator Johnson,...  Kennedy   \n",
       "1  It was my great honor to place his n...  Kennedy   \n",
       "2  With a deep sense of duty and high r...  Kennedy   \n",
       "3  I accept it with a full and grateful...  Kennedy   \n",
       "4  I am grateful, too, that you have pr...  Kennedy   \n",
       "\n",
       "                                   stemmed  stemmed_len  \\\n",
       "0  [governor, stevenson, senat, johnson...           23   \n",
       "1  [It, great, honor, place, name, nomi...           17   \n",
       "2  [with, deep, sens, duti, high, resol...            9   \n",
       "3  [I, accept, full, grate, heartwithou...           22   \n",
       "4  [I, grate, provid, eloqu, statement,...            7   \n",
       "\n",
       "                                 lemmatize  lemmatize_len  \n",
       "0  [Governor, Stevenson, Senator, Johns...             23  \n",
       "1  [It, great, honor, place, name, nomi...             17  \n",
       "2  [With, deep, sense, duty, high, reso...              9  \n",
       "3  [I, accept, full, grateful, heartwit...             22  \n",
       "4  [I, grateful, provided, eloquent, st...              7  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame_Kennedy['stemmed']     = DataFrame_Kennedy['Text'].apply(lambda x: clean_text_stem(x))\n",
    "DataFrame_Kennedy['stemmed_len'] = DataFrame_Kennedy['stemmed'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "DataFrame_Kennedy['lemmatize']    = DataFrame_Kennedy['Text'].apply(lambda x: clean_text_lemmatize(x))\n",
    "DataFrame_Kennedy['lemmatize_len'] = DataFrame_Kennedy['lemmatize'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "DataFrame_Kennedy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stemmed_len</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>lemmatize_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[thank, much]</td>\n",
       "      <td>2</td>\n",
       "      <td>[Thank, much]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We're using up prime time.</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[were, use, prime, time]</td>\n",
       "      <td>4</td>\n",
       "      <td>[Were, using, prime, time]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[thank, much]</td>\n",
       "      <td>2</td>\n",
       "      <td>[Thank, much]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You're singing our song.</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[your, sing, song]</td>\n",
       "      <td>3</td>\n",
       "      <td>[Youre, singing, song]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, the first thrill tonight was t...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[well, first, thrill, tonight, find,...</td>\n",
       "      <td>12</td>\n",
       "      <td>[Well, first, thrill, tonight, find,...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text  Person  \\\n",
       "0                     Thank you very much.  Raegan   \n",
       "1               We're using up prime time.  Raegan   \n",
       "2                     Thank you very much.  Raegan   \n",
       "3                 You're singing our song.  Raegan   \n",
       "4  Well, the first thrill tonight was t...  Raegan   \n",
       "\n",
       "                                   stemmed  stemmed_len  \\\n",
       "0                            [thank, much]            2   \n",
       "1                 [were, use, prime, time]            4   \n",
       "2                            [thank, much]            2   \n",
       "3                       [your, sing, song]            3   \n",
       "4  [well, first, thrill, tonight, find,...           12   \n",
       "\n",
       "                                 lemmatize  lemmatize_len  \n",
       "0                            [Thank, much]              2  \n",
       "1               [Were, using, prime, time]              4  \n",
       "2                            [Thank, much]              2  \n",
       "3                   [Youre, singing, song]              3  \n",
       "4  [Well, first, thrill, tonight, find,...             12  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame_Raegan['stemmed']     = DataFrame_Raegan['Text'].apply(lambda x: clean_text_stem(x))\n",
    "DataFrame_Raegan['stemmed_len'] = DataFrame_Raegan['stemmed'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "DataFrame_Raegan['lemmatize']    = DataFrame_Raegan['Text'].apply(lambda x: clean_text_lemmatize(x))\n",
    "DataFrame_Raegan['lemmatize_len'] = DataFrame_Raegan['lemmatize'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "DataFrame_Raegan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stemmed_len</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>lemmatize_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have many friends to thank tonight.</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[I, mani, friend, thank, tonight]</td>\n",
       "      <td>5</td>\n",
       "      <td>[I, many, friend, thank, tonight]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I thank the voters who supported me.</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[I, thank, voter, support]</td>\n",
       "      <td>4</td>\n",
       "      <td>[I, thank, voter, supported]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thank the gallant men who entered ...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[I, thank, gallant, men, enter, cont...</td>\n",
       "      <td>10</td>\n",
       "      <td>[I, thank, gallant, men, entered, co...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And, for their kind and stirring wor...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[and, kind, stir, word, I, thank, go...</td>\n",
       "      <td>22</td>\n",
       "      <td>[And, kind, stirring, word, I, thank...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I accept your nomination for President.</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[I, accept, nomin, presid]</td>\n",
       "      <td>4</td>\n",
       "      <td>[I, accept, nomination, President]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Person  \\\n",
       "0    I have many friends to thank tonight.   Bush   \n",
       "1     I thank the voters who supported me.   Bush   \n",
       "2  I thank the gallant men who entered ...   Bush   \n",
       "3  And, for their kind and stirring wor...   Bush   \n",
       "4  I accept your nomination for President.   Bush   \n",
       "\n",
       "                                   stemmed  stemmed_len  \\\n",
       "0        [I, mani, friend, thank, tonight]            5   \n",
       "1               [I, thank, voter, support]            4   \n",
       "2  [I, thank, gallant, men, enter, cont...           10   \n",
       "3  [and, kind, stir, word, I, thank, go...           22   \n",
       "4               [I, accept, nomin, presid]            4   \n",
       "\n",
       "                                 lemmatize  lemmatize_len  \n",
       "0        [I, many, friend, thank, tonight]              5  \n",
       "1             [I, thank, voter, supported]              4  \n",
       "2  [I, thank, gallant, men, entered, co...             10  \n",
       "3  [And, kind, stirring, word, I, thank...             22  \n",
       "4       [I, accept, nomination, President]              4  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame_Bush['stemmed']     = DataFrame_Bush['Text'].apply(lambda x: clean_text_stem(x))\n",
    "DataFrame_Bush['stemmed_len'] = DataFrame_Bush['stemmed'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "DataFrame_Bush['lemmatize']    = DataFrame_Bush['Text'].apply(lambda x: clean_text_lemmatize(x))\n",
    "DataFrame_Bush['lemmatize_len'] = DataFrame_Bush['lemmatize'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "DataFrame_Bush.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stemmed_len</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>lemmatize_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To Chairman Dean and my great friend...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[To, chairman, dean, great, friend, ...</td>\n",
       "      <td>21</td>\n",
       "      <td>[To, Chairman, Dean, great, friend, ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Let me express my thanks to the hist...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[let, express, thank, histor, slate,...</td>\n",
       "      <td>22</td>\n",
       "      <td>[Let, express, thanks, historic, sla...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To President Clinton, who last night...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[To, presid, clinton, last, night, m...</td>\n",
       "      <td>23</td>\n",
       "      <td>[To, President, Clinton, last, night...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am grateful to finish this journey...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[I, grate, finish, journey, one, fin...</td>\n",
       "      <td>21</td>\n",
       "      <td>[I, grateful, finish, journey, one, ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To the love of my life, our next fir...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[To, love, life, next, first, ladi, ...</td>\n",
       "      <td>16</td>\n",
       "      <td>[To, love, life, next, first, lady, ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Person  \\\n",
       "0  To Chairman Dean and my great friend...  Obama   \n",
       "1  Let me express my thanks to the hist...  Obama   \n",
       "2  To President Clinton, who last night...  Obama   \n",
       "3  I am grateful to finish this journey...  Obama   \n",
       "4  To the love of my life, our next fir...  Obama   \n",
       "\n",
       "                                   stemmed  stemmed_len  \\\n",
       "0  [To, chairman, dean, great, friend, ...           21   \n",
       "1  [let, express, thank, histor, slate,...           22   \n",
       "2  [To, presid, clinton, last, night, m...           23   \n",
       "3  [I, grate, finish, journey, one, fin...           21   \n",
       "4  [To, love, life, next, first, ladi, ...           16   \n",
       "\n",
       "                                 lemmatize  lemmatize_len  \n",
       "0  [To, Chairman, Dean, great, friend, ...             21  \n",
       "1  [Let, express, thanks, historic, sla...             22  \n",
       "2  [To, President, Clinton, last, night...             23  \n",
       "3  [I, grateful, finish, journey, one, ...             21  \n",
       "4  [To, love, life, next, first, lady, ...             16  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame_Obama['stemmed']     = DataFrame_Obama['Text'].apply(lambda x: clean_text_stem(x))\n",
    "DataFrame_Obama['stemmed_len'] = DataFrame_Obama['stemmed'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "DataFrame_Obama['lemmatize']    = DataFrame_Obama['Text'].apply(lambda x: clean_text_lemmatize(x))\n",
    "DataFrame_Obama['lemmatize_len'] = DataFrame_Obama['lemmatize'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "DataFrame_Obama.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dk = DataFrame_Kennedy.copy()\n",
    "dr = DataFrame_Raegan.copy()\n",
    "db = DataFrame_Bush.copy()\n",
    "do = DataFrame_Obama.copy()\n",
    "\n",
    "dts = [dk, dr, db, do]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kennedy 96 96\n",
      "Raegan 178 178\n",
      "Bush 177 177\n",
      "Obama 168 168\n"
     ]
    }
   ],
   "source": [
    "Num_words_per_sent = 5\n",
    "for dt in dts:\n",
    "    print(dt.loc[0,'Person'],dt[dt['stemmed_len']> Num_words_per_sent][['stemmed_len']].count()[0],dt[dt['stemmed_len']> Num_words_per_sent][['lemmatize_len']].count()[0] ,end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 6)\n"
     ]
    }
   ],
   "source": [
    "condition= (dk['lemmatize_len'] > 5) & (dk['lemmatize_len'] < 50)\n",
    "dk.where(condition,inplace=False).dropna().head(2)\n",
    "print(dk.where(cond=condition,inplace=False).dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dk.sample(n=3,random_state=42).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To require a minimum number of key words in the sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining rows for person Kennedy before was : 127 and now is 121\n",
      "remaining rows for person Raegan before was : 217 and now is 207\n",
      "remaining rows for person Bush before was : 299 and now is 276\n",
      "remaining rows for person Obama before was : 226 and now is 217\n"
     ]
    }
   ],
   "source": [
    "# lets see how many lines in each speech is having minimum of 5 stemmed or lemmatized words\n",
    "for d in dts:\n",
    "    bad_rows = [row for row in d.index if d.loc[row,'lemmatize_len']< 3 ]\n",
    "    print('remaining rows for person {} before was : {} and now is {}'.format(d['Person'].loc[1],len(d), len(d.drop(bad_rows))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram\n",
    "import numpy as np\n",
    "bins = np.linspace(0, 60, 20)\n",
    "plt.hist(dr['lemmatize_len'], bins, alpha=1, density=False, label='Raegan')\n",
    "plt.hist(dk['lemmatize_len'], bins, alpha=1, density=False, label='Kennedy', color= 'red')\n",
    "plt.hist(db['lemmatize_len'], bins, alpha=0.6, density=False, label='Bush', color='b')\n",
    "plt.hist(do['lemmatize_len'], bins, alpha=0.3, density=False, label='Obama')\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "columns = 'lemmatize_len'\n",
    "normed = False\n",
    "ymax = 75\n",
    "\n",
    "bins = np.linspace(0, 60, 30)\n",
    "\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "plt.subplot(141)\n",
    "plt.hist(dr[columns], bins = bins, density=normed, label='Raegan', color='Red')\n",
    "plt.ylim([0, ymax])\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(142)\n",
    "plt.hist(dk[columns], bins =bins, density=normed, label ='Kennedy', color ='black')\n",
    "plt.ylim([0, ymax])\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(143)\n",
    "plt.hist(db[columns], bins =bins, density=normed, label ='Bush', color ='Blue')\n",
    "plt.ylim([0, ymax])\n",
    "plt.legend(loc='upper right')\n",
    "plt.subplot(144)\n",
    "plt.hist(do[columns], bins =bins, density=normed, label ='Obama', color ='purple')\n",
    "plt.ylim([0, ymax])\n",
    "plt.legend(loc='upper right')\n",
    "# fig.tight_layout()\n",
    "plt.show()\n",
    "condition= (dk['lemmatize_len'] > 5) & (dk['lemmatize_len'] < 50)\n",
    "dk.where(condition,inplace=False).dropna().head(2)\n",
    "\n",
    "fig.savefig(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove very short sentences from all speeches\n",
    "for d in [dk, dr, db, do]:\n",
    "    d.where(d['lemmatize_len'] >= 3,inplace=True)\n",
    "    d.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[121, 207, 276, 217]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The new dataframes have this number of sentences\n",
    "[len(d) for d in dts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sents = min([len(d) for d in dts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove very short sentences from all speeches by randomly choosing num_sents from each database\n",
    "dk = dk.sample(n=num_sents,random_state=42).reset_index(drop=True).copy() \n",
    "dr = dr.sample(n=num_sents,random_state=42).reset_index(drop=True).copy()\n",
    "db = db.sample(n=num_sents,random_state=42).reset_index(drop=True).copy()\n",
    "do = do.sample(n=num_sents,random_state=42).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 6)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stemmed_len</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>lemmatize_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But I am here tonight - and I am you...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[but, I, tonight, I, candid, import,...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[But, I, tonight, I, candidate, impo...</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate war.</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[I, hate, war]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[I, hate, war]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Zero tolerance\" isn't just a policy...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[zero, toler, isnt, polici, attitud]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Zero, tolerance, isnt, policy, atti...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our economy is strong but not invuln...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[our, economi, strong, invulner, pea...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[Our, economy, strong, invulnerable,...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We're on a journey to a new century,...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[were, journey, new, centuri, weve, ...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[Were, journey, new, century, weve, ...</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Person  \\\n",
       "0  But I am here tonight - and I am you...   Bush   \n",
       "1                              I hate war.   Bush   \n",
       "2  \"Zero tolerance\" isn't just a policy...   Bush   \n",
       "3  Our economy is strong but not invuln...   Bush   \n",
       "4  We're on a journey to a new century,...   Bush   \n",
       "\n",
       "                                   stemmed  stemmed_len  \\\n",
       "0  [but, I, tonight, I, candid, import,...         12.0   \n",
       "1                           [I, hate, war]          3.0   \n",
       "2     [zero, toler, isnt, polici, attitud]          5.0   \n",
       "3  [our, economi, strong, invulner, pea...          7.0   \n",
       "4  [were, journey, new, centuri, weve, ...         12.0   \n",
       "\n",
       "                                 lemmatize  lemmatize_len  \n",
       "0  [But, I, tonight, I, candidate, impo...           12.0  \n",
       "1                           [I, hate, war]            3.0  \n",
       "2  [Zero, tolerance, isnt, policy, atti...            5.0  \n",
       "3  [Our, economy, strong, invulnerable,...            7.0  \n",
       "4  [Were, journey, new, century, weve, ...           12.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization using tf-idf and preparing features and lables for model trainig\n",
    "## Work based on stemmed or lemmatized\n",
    "## keep 80% for training and rest for final test evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define clean function\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all dataframes together to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bundle all data into one dataframe and then shuffle couple of times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484, 6)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data = pd.concat([dk, db,dr,do], axis =0)\n",
    "big_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the rows using 100% sampling without replacement and resetting the index\n",
    "\n",
    "(shuffling three times because... it sounds better than once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stemmed_len</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>lemmatize_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a Platform on which I can ru...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[thi, platform, I, run, enthusiasm, ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[This, Platform, I, run, enthusiasm,...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's not the judgment we need.</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[that, judgment, need]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Thats, judgment, need]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>America, now is not the time for sma...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[america, time, small, plan]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[America, time, small, plan]</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One-third of the world, it has been ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[onethird, world, said, may, free, o...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[Onethird, world, said, may, free, o...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our task is not merely one of itemiz...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[our, task, mere, one, item, republi...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[Our, task, merely, one, itemizing, ...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>And so I know that what it all comes...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[and, I, know, come, elect, come, sh...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[And, I, know, come, election, come,...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>As for me, I have held high office a...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[As, I, held, high, offic, done, wor...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[As, I, held, high, office, done, wo...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Weakness and ambivalence lead to war.</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[weak, ambival, lead, war]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Weakness, ambivalence, lead, war]</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In the Republicans who never thought...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[In, republican, never, thought, the...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[In, Republicans, never, thought, th...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>That is the question of the New Fron...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[that, question, new, frontier]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[That, question, New, Frontier]</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I want to stress, what some other po...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[I, want, stress, polit, religi, lea...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[I, want, stress, political, religio...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>As we face the coming challenge, we ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[As, face, come, challeng, shall, wa...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[As, face, coming, challenge, shall,...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"The Rights of Man\"--the civil and e...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[the, right, manth, civil, econom, r...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[The, Rights, Manthe, civil, economi...</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Abroad, the balance of power is shif...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[abroad, balanc, power, shift]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Abroad, balance, power, shifting]</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>America, this is one of those moments.</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[america, one, moment]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[America, one, moment]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>That is the real question.</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[that, real, question]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[That, real, question]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>But we are not merely running agains...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[but, mere, run, Mr, nixon]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[But, merely, running, Mr, Nixon]</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>It should ensure opportunity not jus...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[It, ensur, opportun, money, influen...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[It, ensure, opportunity, money, inf...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"And as we walk, we must make the pl...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[and, walk, must, make, pledg, shall...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[And, walk, must, make, pledge, shal...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A whole world looks to see what we w...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[A, whole, world, look, see]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[A, whole, world, look, see]</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>And that is the idea of community - ...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[and, idea, commun, beauti, word, bi...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[And, idea, community, beautiful, wo...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>They were not the captives of their ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[they, captiv, doubt, prison, price,...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[They, captive, doubt, prisoner, pri...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>You don't defeat a terrorist network...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[you, dont, defeat, terrorist, netwo...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[You, dont, defeat, terrorist, netwo...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Franklin Roosevelt's New Deal promis...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[franklin, roosevelt, new, deal, pro...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[Franklin, Roosevelts, New, Deal, pr...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I have come to this hall to tell you...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[I, come, hall, tell, tell, america,...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[I, come, hall, tell, tell, America,...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I believe that as hard as it will be...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[I, believ, hard, chang, need, come]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[I, believe, hard, change, need, com...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I am telling you now what you are en...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[I, tell, entitl, know, decis, publi...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[I, telling, entitled, know, decisio...</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I don't know about you, but I'm not ...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[I, dont, know, Im, readi, take, 10,...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[I, dont, know, Im, ready, take, 10,...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>To those young people I say \" You ha...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[To, young, peopl, I, say, you, oppo...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[To, young, people, I, say, You, opp...</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>But you and I live in a real world, ...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[but, I, live, real, world, disast, ...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[But, I, live, real, world, disaster...</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>For the world is changing.</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[for, world, chang]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[For, world, changing]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Nimitz, which was returning from lon...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[nimitz, return, long, month, duti, ...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[Nimitz, returning, long, month, dut...</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>We cut them in half.</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[We, cut, half]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[We, cut, half]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>For 18 long months, you have stood u...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[for, 18, long, month, stood, one, o...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[For, 18, long, month, stood, one, o...</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>I thank the gallant men who entered ...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[I, thank, gallant, men, enter, cont...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[I, thank, gallant, men, entered, co...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>And you must know us.</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[and, must, know, us]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[And, must, know, u]</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>A nation of whiners?</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[A, nation, whiner]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[A, nation, whiner]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>These are concepts that stem from an...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[these, concept, stem, econom, syste...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[These, concept, stem, economic, sys...</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>For example, Mr. Carter says he supp...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[for, exampl, Mr, carter, say, suppo...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[For, example, Mr, Carter, say, supp...</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>We measure progress by how many peop...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[We, measur, progress, mani, peopl, ...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>[We, measure, progress, many, people...</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>I have seen the unexpected crisis th...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[I, seen, unexpect, crisi, arriv, ca...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[I, seen, unexpected, crisis, arrive...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>He said:\\n\\n\"For three long years I ...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[He, said, for, three, long, year, I...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[He, said, For, three, long, year, I...</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Not with so many families to protect...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[not, mani, famili, protect, mani, l...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[Not, many, family, protect, many, l...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Reenlistment rates drop and, just re...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[reenlist, rate, drop, recent, fough...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[Reenlistment, rate, drop, recently,...</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>America, we cannot turn back.</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[america, cannot, turn, back]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[America, cannot, turn, back]</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>For the harsh facts of the matter ar...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[for, harsh, fact, matter, stand, fr...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[For, harsh, fact, matter, stand, fr...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>It's an economic stew that has turne...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[it, econom, stew, turn, nation, sto...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[Its, economic, stew, turned, nation...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>You don't protect Israel and deter I...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[you, dont, protect, israel, deter, ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[You, dont, protect, Israel, deter, ...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>You know, there may be a sailor at t...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[you, know, may, sailor, helm, ship,...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[You, know, may, sailor, helm, ship,...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Give me your help, your hand, your v...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[give, help, hand, voic, vote]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Give, help, hand, voice, vote]</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>Never before in our history have Ame...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[never, histori, american, call, upo...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[Never, history, Americans, called, ...</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>We have come together here because t...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[We, come, togeth, american, peopl, ...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[We, come, together, American, peopl...</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>I am grateful, too, that you have pr...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[I, grate, provid, eloqu, statement,...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[I, grateful, provided, eloquent, st...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>My call is to the young in heart, re...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[My, call, young, heart, regardless,...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>[My, call, young, heart, regardless,...</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>Meanwhile, Communist influence has p...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[meanwhil, communist, influenc, pene...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[Meanwhile, Communist, influence, pe...</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>I do so with deep gratitude.</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[I, deep, gratitud]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[I, deep, gratitude]</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>I'll make it easier for the American...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[ill, make, easier, american, peopl,...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[Ill, make, easier, American, people...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Thanks to the economic policies of t...</td>\n",
       "      <td>Raegan</td>\n",
       "      <td>[thank, econom, polici, democrat, pa...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[Thanks, economic, policy, Democrati...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>I believe in another tradition that ...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[I, believ, anoth, tradit, embed, na...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[I, believe, another, tradition, emb...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>I am going to have the FBI trace the...</td>\n",
       "      <td>Bush</td>\n",
       "      <td>[I, go, fbi, trace, medic, wast, go,...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[I, going, FBI, trace, medical, wast...</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Text   Person  \\\n",
       "0    This is a Platform on which I can ru...  Kennedy   \n",
       "1           That's not the judgment we need.    Obama   \n",
       "2    America, now is not the time for sma...    Obama   \n",
       "3    One-third of the world, it has been ...  Kennedy   \n",
       "4    Our task is not merely one of itemiz...  Kennedy   \n",
       "5    And so I know that what it all comes...     Bush   \n",
       "6    As for me, I have held high office a...     Bush   \n",
       "7      Weakness and ambivalence lead to war.     Bush   \n",
       "8    In the Republicans who never thought...    Obama   \n",
       "9    That is the question of the New Fron...  Kennedy   \n",
       "10   I want to stress, what some other po...  Kennedy   \n",
       "11   As we face the coming challenge, we ...  Kennedy   \n",
       "12   \"The Rights of Man\"--the civil and e...  Kennedy   \n",
       "13   Abroad, the balance of power is shif...  Kennedy   \n",
       "14    America, this is one of those moments.    Obama   \n",
       "15                That is the real question.  Kennedy   \n",
       "16   But we are not merely running agains...  Kennedy   \n",
       "17   It should ensure opportunity not jus...    Obama   \n",
       "18   \"And as we walk, we must make the pl...    Obama   \n",
       "19   A whole world looks to see what we w...  Kennedy   \n",
       "20   And that is the idea of community - ...     Bush   \n",
       "21   They were not the captives of their ...  Kennedy   \n",
       "22   You don't defeat a terrorist network...    Obama   \n",
       "23   Franklin Roosevelt's New Deal promis...  Kennedy   \n",
       "24   I have come to this hall to tell you...     Bush   \n",
       "25   I believe that as hard as it will be...    Obama   \n",
       "26   I am telling you now what you are en...  Kennedy   \n",
       "27   I don't know about you, but I'm not ...    Obama   \n",
       "28   To those young people I say \" You ha...     Bush   \n",
       "29   But you and I live in a real world, ...   Raegan   \n",
       "..                                       ...      ...   \n",
       "454               For the world is changing.  Kennedy   \n",
       "455  Nimitz, which was returning from lon...   Raegan   \n",
       "456                     We cut them in half.     Bush   \n",
       "457  For 18 long months, you have stood u...    Obama   \n",
       "458  I thank the gallant men who entered ...     Bush   \n",
       "459                    And you must know us.     Bush   \n",
       "460                     A nation of whiners?    Obama   \n",
       "461  These are concepts that stem from an...   Raegan   \n",
       "462  For example, Mr. Carter says he supp...   Raegan   \n",
       "463  We measure progress by how many peop...    Obama   \n",
       "464  I have seen the unexpected crisis th...     Bush   \n",
       "465  He said:\\n\\n\"For three long years I ...   Raegan   \n",
       "466  Not with so many families to protect...    Obama   \n",
       "467  Reenlistment rates drop and, just re...   Raegan   \n",
       "468            America, we cannot turn back.    Obama   \n",
       "469  For the harsh facts of the matter ar...  Kennedy   \n",
       "470  It's an economic stew that has turne...   Raegan   \n",
       "471  You don't protect Israel and deter I...    Obama   \n",
       "472  You know, there may be a sailor at t...   Raegan   \n",
       "473  Give me your help, your hand, your v...  Kennedy   \n",
       "474  Never before in our history have Ame...   Raegan   \n",
       "475  We have come together here because t...   Raegan   \n",
       "476  I am grateful, too, that you have pr...  Kennedy   \n",
       "477  My call is to the young in heart, re...  Kennedy   \n",
       "478  Meanwhile, Communist influence has p...  Kennedy   \n",
       "479             I do so with deep gratitude.   Raegan   \n",
       "480  I'll make it easier for the American...    Obama   \n",
       "481  Thanks to the economic policies of t...   Raegan   \n",
       "482  I believe in another tradition that ...     Bush   \n",
       "483  I am going to have the FBI trace the...     Bush   \n",
       "\n",
       "                                     stemmed  stemmed_len  \\\n",
       "0    [thi, platform, I, run, enthusiasm, ...          6.0   \n",
       "1                     [that, judgment, need]          3.0   \n",
       "2               [america, time, small, plan]          4.0   \n",
       "3    [onethird, world, said, may, free, o...         16.0   \n",
       "4    [our, task, mere, one, item, republi...          7.0   \n",
       "5    [and, I, know, come, elect, come, sh...         10.0   \n",
       "6    [As, I, held, high, offic, done, wor...         10.0   \n",
       "7                 [weak, ambival, lead, war]          4.0   \n",
       "8    [In, republican, never, thought, the...          8.0   \n",
       "9            [that, question, new, frontier]          4.0   \n",
       "10   [I, want, stress, polit, religi, lea...          9.0   \n",
       "11   [As, face, come, challeng, shall, wa...         11.0   \n",
       "12   [the, right, manth, civil, econom, r...         14.0   \n",
       "13            [abroad, balanc, power, shift]          4.0   \n",
       "14                    [america, one, moment]          3.0   \n",
       "15                    [that, real, question]          3.0   \n",
       "16               [but, mere, run, Mr, nixon]          5.0   \n",
       "17   [It, ensur, opportun, money, influen...         10.0   \n",
       "18   [and, walk, must, make, pledg, shall...          9.0   \n",
       "19              [A, whole, world, look, see]          5.0   \n",
       "20   [and, idea, commun, beauti, word, bi...          7.0   \n",
       "21   [they, captiv, doubt, prison, price,...          6.0   \n",
       "22   [you, dont, defeat, terrorist, netwo...         10.0   \n",
       "23   [franklin, roosevelt, new, deal, pro...          8.0   \n",
       "24   [I, come, hall, tell, tell, america,...          8.0   \n",
       "25      [I, believ, hard, chang, need, come]          6.0   \n",
       "26   [I, tell, entitl, know, decis, publi...         12.0   \n",
       "27   [I, dont, know, Im, readi, take, 10,...         10.0   \n",
       "28   [To, young, peopl, I, say, you, oppo...         13.0   \n",
       "29   [but, I, live, real, world, disast, ...         12.0   \n",
       "..                                       ...          ...   \n",
       "454                      [for, world, chang]          3.0   \n",
       "455  [nimitz, return, long, month, duti, ...         14.0   \n",
       "456                          [We, cut, half]          3.0   \n",
       "457  [for, 18, long, month, stood, one, o...         11.0   \n",
       "458  [I, thank, gallant, men, enter, cont...         10.0   \n",
       "459                    [and, must, know, us]          4.0   \n",
       "460                      [A, nation, whiner]          3.0   \n",
       "461  [these, concept, stem, econom, syste...         40.0   \n",
       "462  [for, exampl, Mr, carter, say, suppo...         21.0   \n",
       "463  [We, measur, progress, mani, peopl, ...         23.0   \n",
       "464  [I, seen, unexpect, crisi, arriv, ca...          9.0   \n",
       "465  [He, said, for, three, long, year, I...         16.0   \n",
       "466  [not, mani, famili, protect, mani, l...          7.0   \n",
       "467  [reenlist, rate, drop, recent, fough...         15.0   \n",
       "468            [america, cannot, turn, back]          4.0   \n",
       "469  [for, harsh, fact, matter, stand, fr...          8.0   \n",
       "470  [it, econom, stew, turn, nation, sto...          6.0   \n",
       "471  [you, dont, protect, israel, deter, ...          9.0   \n",
       "472  [you, know, may, sailor, helm, ship,...          9.0   \n",
       "473           [give, help, hand, voic, vote]          5.0   \n",
       "474  [never, histori, american, call, upo...         14.0   \n",
       "475  [We, come, togeth, american, peopl, ...         15.0   \n",
       "476  [I, grate, provid, eloqu, statement,...          7.0   \n",
       "477  [My, call, young, heart, regardless,...         17.0   \n",
       "478  [meanwhil, communist, influenc, pene...         14.0   \n",
       "479                      [I, deep, gratitud]          3.0   \n",
       "480  [ill, make, easier, american, peopl,...          8.0   \n",
       "481  [thank, econom, polici, democrat, pa...          9.0   \n",
       "482  [I, believ, anoth, tradit, embed, na...          7.0   \n",
       "483  [I, go, fbi, trace, medic, wast, go,...         15.0   \n",
       "\n",
       "                                   lemmatize  lemmatize_len  \n",
       "0    [This, Platform, I, run, enthusiasm,...            6.0  \n",
       "1                    [Thats, judgment, need]            3.0  \n",
       "2               [America, time, small, plan]            4.0  \n",
       "3    [Onethird, world, said, may, free, o...           16.0  \n",
       "4    [Our, task, merely, one, itemizing, ...            7.0  \n",
       "5    [And, I, know, come, election, come,...           10.0  \n",
       "6    [As, I, held, high, office, done, wo...           10.0  \n",
       "7         [Weakness, ambivalence, lead, war]            4.0  \n",
       "8    [In, Republicans, never, thought, th...            8.0  \n",
       "9            [That, question, New, Frontier]            4.0  \n",
       "10   [I, want, stress, political, religio...            9.0  \n",
       "11   [As, face, coming, challenge, shall,...           11.0  \n",
       "12   [The, Rights, Manthe, civil, economi...           14.0  \n",
       "13        [Abroad, balance, power, shifting]            4.0  \n",
       "14                    [America, one, moment]            3.0  \n",
       "15                    [That, real, question]            3.0  \n",
       "16         [But, merely, running, Mr, Nixon]            5.0  \n",
       "17   [It, ensure, opportunity, money, inf...           10.0  \n",
       "18   [And, walk, must, make, pledge, shal...            9.0  \n",
       "19              [A, whole, world, look, see]            5.0  \n",
       "20   [And, idea, community, beautiful, wo...            7.0  \n",
       "21   [They, captive, doubt, prisoner, pri...            6.0  \n",
       "22   [You, dont, defeat, terrorist, netwo...           10.0  \n",
       "23   [Franklin, Roosevelts, New, Deal, pr...            8.0  \n",
       "24   [I, come, hall, tell, tell, America,...            8.0  \n",
       "25   [I, believe, hard, change, need, com...            6.0  \n",
       "26   [I, telling, entitled, know, decisio...           12.0  \n",
       "27   [I, dont, know, Im, ready, take, 10,...           10.0  \n",
       "28   [To, young, people, I, say, You, opp...           13.0  \n",
       "29   [But, I, live, real, world, disaster...           12.0  \n",
       "..                                       ...            ...  \n",
       "454                   [For, world, changing]            3.0  \n",
       "455  [Nimitz, returning, long, month, dut...           14.0  \n",
       "456                          [We, cut, half]            3.0  \n",
       "457  [For, 18, long, month, stood, one, o...           11.0  \n",
       "458  [I, thank, gallant, men, entered, co...           10.0  \n",
       "459                     [And, must, know, u]            4.0  \n",
       "460                      [A, nation, whiner]            3.0  \n",
       "461  [These, concept, stem, economic, sys...           40.0  \n",
       "462  [For, example, Mr, Carter, say, supp...           21.0  \n",
       "463  [We, measure, progress, many, people...           23.0  \n",
       "464  [I, seen, unexpected, crisis, arrive...            9.0  \n",
       "465  [He, said, For, three, long, year, I...           16.0  \n",
       "466  [Not, many, family, protect, many, l...            7.0  \n",
       "467  [Reenlistment, rate, drop, recently,...           15.0  \n",
       "468            [America, cannot, turn, back]            4.0  \n",
       "469  [For, harsh, fact, matter, stand, fr...            8.0  \n",
       "470  [Its, economic, stew, turned, nation...            6.0  \n",
       "471  [You, dont, protect, Israel, deter, ...            9.0  \n",
       "472  [You, know, may, sailor, helm, ship,...            9.0  \n",
       "473          [Give, help, hand, voice, vote]            5.0  \n",
       "474  [Never, history, Americans, called, ...           14.0  \n",
       "475  [We, come, together, American, peopl...           15.0  \n",
       "476  [I, grateful, provided, eloquent, st...            7.0  \n",
       "477  [My, call, young, heart, regardless,...           17.0  \n",
       "478  [Meanwhile, Communist, influence, pe...           14.0  \n",
       "479                     [I, deep, gratitude]            3.0  \n",
       "480  [Ill, make, easier, American, people...            8.0  \n",
       "481  [Thanks, economic, policy, Democrati...            9.0  \n",
       "482  [I, believe, another, tradition, emb...            7.0  \n",
       "483  [I, going, FBI, trace, medical, wast...           15.0  \n",
       "\n",
       "[484 rows x 6 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's shuffle three times\n",
    "big_data = big_data.sample(frac=1,replace=False, random_state=42).reset_index(drop=True)\n",
    "big_data = big_data.sample(frac=1,replace=False, random_state=42).reset_index(drop=True)\n",
    "big_data = big_data.sample(frac=1,replace=False, random_state=42).reset_index(drop=True)\n",
    "big_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the length of raw sentence as a feature to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stemmed_len</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>lemmatize_len</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a Platform on which I can ru...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[thi, platform, I, run, enthusiasm, ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[This, Platform, I, run, enthusiasm,...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's not the judgment we need.</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[that, judgment, need]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Thats, judgment, need]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>America, now is not the time for sma...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[america, time, small, plan]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[America, time, small, plan]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One-third of the world, it has been ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[onethird, world, said, may, free, o...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[Onethird, world, said, may, free, o...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our task is not merely one of itemiz...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[our, task, mere, one, item, republi...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[Our, task, merely, one, itemizing, ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text   Person  \\\n",
       "0  This is a Platform on which I can ru...  Kennedy   \n",
       "1         That's not the judgment we need.    Obama   \n",
       "2  America, now is not the time for sma...    Obama   \n",
       "3  One-third of the world, it has been ...  Kennedy   \n",
       "4  Our task is not merely one of itemiz...  Kennedy   \n",
       "\n",
       "                                   stemmed  stemmed_len  \\\n",
       "0  [thi, platform, I, run, enthusiasm, ...          6.0   \n",
       "1                   [that, judgment, need]          3.0   \n",
       "2             [america, time, small, plan]          4.0   \n",
       "3  [onethird, world, said, may, free, o...         16.0   \n",
       "4  [our, task, mere, one, item, republi...          7.0   \n",
       "\n",
       "                                 lemmatize  lemmatize_len  text_len  \n",
       "0  [This, Platform, I, run, enthusiasm,...            6.0        57  \n",
       "1                  [Thats, judgment, need]            3.0        27  \n",
       "2             [America, time, small, plan]            4.0        37  \n",
       "3  [Onethird, world, said, may, free, o...           16.0       149  \n",
       "4  [Our, task, merely, one, itemizing, ...            7.0        51  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data['text_len'] = big_data['Text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "big_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double check if sampling took all databases correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text             True\n",
       "Person           True\n",
       "stemmed          True\n",
       "stemmed_len      True\n",
       "lemmatize        True\n",
       "lemmatize_len    True\n",
       "text_len         True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_data[big_data['Person']=='Raegan'].count()==big_data[big_data['Person']=='Kennedy'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is when the train_test split is happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(big_data[['Text', 'text_len', 'stemmed_len']],\n",
    "                                                    big_data['Person'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (387, 3) \n",
      "test:  (97, 3)\n"
     ]
    }
   ],
   "source": [
    "# see the actual number of senteces for train and test\n",
    "print('train: {} \\ntest:  {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The index for `pd.DataFrame(tfidf_train.toarray())]` starts from 0 unlike the `X_train[['text_len', 'stemmed_len']]` which has the original index, therefore we have to reset the index for `X_train[['text_len', 'stemmed_len']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>stemmed_len</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>1493</th>\n",
       "      <th>1494</th>\n",
       "      <th>1495</th>\n",
       "      <th>1496</th>\n",
       "      <th>1497</th>\n",
       "      <th>1498</th>\n",
       "      <th>1499</th>\n",
       "      <th>1500</th>\n",
       "      <th>1501</th>\n",
       "      <th>1502</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_len  stemmed_len    0    1    2    3    4    5    6    7  ...  1493  \\\n",
       "0       168         19.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "1        40          5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "2       109         13.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "3        26          3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "4        31          5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "   1494  1495  1496  1497  1498  1499  1500  1501      1502  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.184486  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "\n",
       "[5 rows x 1505 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['Text'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['Text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['Text'])\n",
    "\n",
    "X_train_vect = pd.concat([X_train[['text_len', 'stemmed_len']].reset_index(drop=True), \n",
    "                          pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "\n",
    "X_test_vect = pd.concat([X_test[['text_len', 'stemmed_len']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray())], axis=1)\n",
    "\n",
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218      Obama\n",
       "16     Kennedy\n",
       "291       Bush\n",
       "406       Bush\n",
       "107    Kennedy\n",
       "Name: Person, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time 0.111\n",
      "precision 0.433\n",
      "accuracy_score 0.433\n",
      "recall_score 0.433\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = rf_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "\n",
    "print('Fit time',round(pred_time,3))\n",
    "print('precision',round(precision_score(y_test, y_pred,average='micro'),3))\n",
    "print('accuracy_score',round(precision_score(y_test, y_pred,average='micro'),3))    \n",
    "print('recall_score',round(precision_score(y_test, y_pred,average='micro'),3))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring parameter settings using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to suspend the future warnings that can be troublesome specially for MLP\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.636797</td>\n",
       "      <td>0.027426</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 150}</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.032431</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.964401</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.945338</td>\n",
       "      <td>0.967846</td>\n",
       "      <td>0.964497</td>\n",
       "      <td>0.010097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.631035</td>\n",
       "      <td>0.112422</td>\n",
       "      <td>0.069412</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532300</td>\n",
       "      <td>0.030426</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.146029</td>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.014132</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': ...</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529716</td>\n",
       "      <td>0.024043</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.272973</td>\n",
       "      <td>0.130165</td>\n",
       "      <td>0.060085</td>\n",
       "      <td>0.018662</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 300}</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524548</td>\n",
       "      <td>0.031425</td>\n",
       "      <td>4</td>\n",
       "      <td>0.980519</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.964401</td>\n",
       "      <td>0.938907</td>\n",
       "      <td>0.974277</td>\n",
       "      <td>0.965796</td>\n",
       "      <td>0.014418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.734995</td>\n",
       "      <td>0.032706</td>\n",
       "      <td>0.034435</td>\n",
       "      <td>0.008466</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524548</td>\n",
       "      <td>0.030755</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1        0.636797      0.027426         0.028334        0.002573   \n",
       "5        1.631035      0.112422         0.069412        0.019392   \n",
       "10       0.931887      0.146029         0.039893        0.014132   \n",
       "2        1.272973      0.130165         0.060085        0.018662   \n",
       "4        0.734995      0.032706         0.034435        0.008466   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "1               30                150   \n",
       "5               60                300   \n",
       "10            None                150   \n",
       "2               30                300   \n",
       "4               60                150   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "1    {'max_depth': 30, 'n_estimators': 150}           0.607595   \n",
       "5    {'max_depth': 60, 'n_estimators': 300}           0.544304   \n",
       "10  {'max_depth': None, 'n_estimators': ...           0.569620   \n",
       "2    {'max_depth': 30, 'n_estimators': 300}           0.569620   \n",
       "4    {'max_depth': 60, 'n_estimators': 150}           0.582278   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "1            0.576923           0.538462  ...         0.558140   \n",
       "5            0.564103           0.538462  ...         0.532300   \n",
       "10           0.512821           0.525641  ...         0.529716   \n",
       "2            0.525641           0.538462  ...         0.524548   \n",
       "4            0.500000           0.525641  ...         0.524548   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "1         0.032431                1            0.974026            0.964401   \n",
       "5         0.030426                2            1.000000            1.000000   \n",
       "10        0.024043                3            1.000000            1.000000   \n",
       "2         0.031425                4            0.980519            0.970874   \n",
       "4         0.030755                4            1.000000            1.000000   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "1             0.970874            0.945338            0.967846   \n",
       "5             1.000000            1.000000            1.000000   \n",
       "10            1.000000            1.000000            1.000000   \n",
       "2             0.964401            0.938907            0.974277   \n",
       "4             1.000000            1.000000            1.000000   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "1           0.964497         0.010097  \n",
       "5           1.000000         0.000000  \n",
       "10          1.000000         0.000000  \n",
       "2           0.965796         0.014418  \n",
       "4           1.000000         0.000000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "        'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_train_vect, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52564103, 0.44871795, 0.62337662, 0.42857143, 0.51948052])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = gs_fit.best_estimator_\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf, X_train_vect, y_train, cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus on negative statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Person</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>stemmed_len</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>lemmatize_len</th>\n",
       "      <th>text_len</th>\n",
       "      <th>POSITIVITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a Platform on which I can ru...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[thi, platform, I, run, enthusiasm, ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[This, Platform, I, run, enthusiasm,...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's not the judgment we need.</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[that, judgment, need]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[Thats, judgment, need]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>America, now is not the time for sma...</td>\n",
       "      <td>Obama</td>\n",
       "      <td>[america, time, small, plan]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[America, time, small, plan]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One-third of the world, it has been ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[onethird, world, said, may, free, o...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[Onethird, world, said, may, free, o...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>149</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our task is not merely one of itemiz...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[our, task, mere, one, item, republi...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[Our, task, merely, one, itemizing, ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text   Person  \\\n",
       "0  This is a Platform on which I can ru...  Kennedy   \n",
       "1         That's not the judgment we need.    Obama   \n",
       "2  America, now is not the time for sma...    Obama   \n",
       "3  One-third of the world, it has been ...  Kennedy   \n",
       "4  Our task is not merely one of itemiz...  Kennedy   \n",
       "\n",
       "                                   stemmed  stemmed_len  \\\n",
       "0  [thi, platform, I, run, enthusiasm, ...          6.0   \n",
       "1                   [that, judgment, need]          3.0   \n",
       "2             [america, time, small, plan]          4.0   \n",
       "3  [onethird, world, said, may, free, o...         16.0   \n",
       "4  [our, task, mere, one, item, republi...          7.0   \n",
       "\n",
       "                                 lemmatize  lemmatize_len  text_len  \\\n",
       "0  [This, Platform, I, run, enthusiasm,...            6.0        57   \n",
       "1                  [Thats, judgment, need]            3.0        27   \n",
       "2             [America, time, small, plan]            4.0        37   \n",
       "3  [Onethird, world, said, may, free, o...           16.0       149   \n",
       "4  [Our, task, merely, one, itemizing, ...            7.0        51   \n",
       "\n",
       "   POSITIVITY  \n",
       "0           1  \n",
       "1           0  \n",
       "2           0  \n",
       "3          -1  \n",
       "4          -1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentients =[]\n",
    "for row in range(len(big_data)):\n",
    "    ss = sid.polarity_scores(big_data.loc[row, 'Text'])\n",
    "    if ss['compound'] < 0 : \n",
    "        sentients.append(-1)\n",
    "    elif ss['compound'] > 0:\n",
    "        sentients.append(1)\n",
    "    else:\n",
    "        sentients.append(0)\n",
    "sentients[:100]\n",
    "big_data['POSITIVITY'] = sentients\n",
    "big_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(big_data[['Text', 'text_len', 'stemmed_len', 'POSITIVITY']],\n",
    "                                                    big_data['Person'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (387, 4) \n",
      "test:  (97, 4)\n"
     ]
    }
   ],
   "source": [
    "# see the actual number of senteces for train and test\n",
    "print('train: {} \\ntest:  {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_len</th>\n",
       "      <th>stemmed_len</th>\n",
       "      <th>POSITIVITY</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>1460</th>\n",
       "      <th>1461</th>\n",
       "      <th>1462</th>\n",
       "      <th>1463</th>\n",
       "      <th>1464</th>\n",
       "      <th>1465</th>\n",
       "      <th>1466</th>\n",
       "      <th>1467</th>\n",
       "      <th>1468</th>\n",
       "      <th>1469</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1473 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_len  stemmed_len  POSITIVITY    0    1    2    3    4    5    6  ...  \\\n",
       "0        43          7.0           1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1        55          8.0           0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2       133         14.0          -1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3        89         11.0           0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4        78          8.0           0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "       1460  1461  1462  1463  1464  1465  1466  1467  1468      1469  \n",
       "0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "1  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "2  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.245949  \n",
       "3  0.246558   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "4  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n",
       "\n",
       "[5 rows x 1473 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The index for `pd.DataFrame(tfidf_train.toarray())]` starts from 0 unlike the `X_train[['text_len', 'stemmed_len']]` which has the original index, therefore we have to reset the index for `X_train[['text_len', 'stemmed_len']]`\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['Text'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['Text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['Text'])\n",
    "\n",
    "X_train_vect = pd.concat([X_train[['text_len', 'stemmed_len', 'POSITIVITY']].reset_index(drop=True), \n",
    "                          pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "\n",
    "X_test_vect = pd.concat([X_test[['text_len', 'stemmed_len', 'POSITIVITY']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray())], axis=1)\n",
    "\n",
    "X_train_vect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf       = RandomForestClassifier(n_estimators=150, max_depth=None, n_jobs=-1)\n",
    "rf_model = rf.fit(X_train_vect, y_train)\n",
    "y_pred   = rf_model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time 0.111\n",
      "precision 0.546\n",
      "accuracy_score 0.546\n",
      "recall_score 0.546\n"
     ]
    }
   ],
   "source": [
    "print('Fit time',round(pred_time,3))\n",
    "print('precision',round(precision_score(y_test, y_pred,average='micro'),3))\n",
    "print('accuracy_score',round(precision_score(y_test, y_pred,average='micro'),3))    \n",
    "print('recall_score',round(precision_score(y_test, y_pred,average='micro'),3))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.142517</td>\n",
       "      <td>0.288384</td>\n",
       "      <td>0.057447</td>\n",
       "      <td>0.023076</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496124</td>\n",
       "      <td>0.048287</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.982152</td>\n",
       "      <td>0.087771</td>\n",
       "      <td>0.038495</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496124</td>\n",
       "      <td>0.019002</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.734619</td>\n",
       "      <td>0.032924</td>\n",
       "      <td>0.046275</td>\n",
       "      <td>0.019458</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 150}</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490956</td>\n",
       "      <td>0.028757</td>\n",
       "      <td>3</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.980707</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>0.984491</td>\n",
       "      <td>0.008027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.245643</td>\n",
       "      <td>0.422374</td>\n",
       "      <td>0.035181</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': ...</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490956</td>\n",
       "      <td>0.041364</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.017958</td>\n",
       "      <td>0.502104</td>\n",
       "      <td>0.060038</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 300}</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.041989</td>\n",
       "      <td>5</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.987055</td>\n",
       "      <td>0.987138</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>0.989013</td>\n",
       "      <td>0.002598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4        1.142517      0.288384         0.057447        0.023076   \n",
       "7        0.982152      0.087771         0.038495        0.004260   \n",
       "1        0.734619      0.032924         0.046275        0.019458   \n",
       "11       1.245643      0.422374         0.035181        0.007144   \n",
       "2        2.017958      0.502104         0.060038        0.011482   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "4               60                150   \n",
       "7               90                150   \n",
       "1               30                150   \n",
       "11            None                300   \n",
       "2               30                300   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "4    {'max_depth': 60, 'n_estimators': 150}           0.556962   \n",
       "7    {'max_depth': 90, 'n_estimators': 150}           0.518987   \n",
       "1    {'max_depth': 30, 'n_estimators': 150}           0.518987   \n",
       "11  {'max_depth': None, 'n_estimators': ...           0.518987   \n",
       "2    {'max_depth': 30, 'n_estimators': 300}           0.518987   \n",
       "\n",
       "    split1_test_score  split2_test_score  ...  mean_test_score  \\\n",
       "4            0.461538           0.461538  ...         0.496124   \n",
       "7            0.474359           0.500000  ...         0.496124   \n",
       "1            0.487179           0.448718  ...         0.490956   \n",
       "11           0.448718           0.512821  ...         0.490956   \n",
       "2            0.474359           0.461538  ...         0.488372   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "4         0.048287                1            1.000000            1.000000   \n",
       "7         0.019002                1            1.000000            1.000000   \n",
       "1         0.028757                3            0.987013            0.990291   \n",
       "11        0.041364                3            1.000000            1.000000   \n",
       "2         0.041989                5            0.987013            0.990291   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "4             1.000000            1.000000            1.000000   \n",
       "7             1.000000            1.000000            1.000000   \n",
       "1             0.970874            0.980707            0.993569   \n",
       "11            1.000000            1.000000            1.000000   \n",
       "2             0.987055            0.987138            0.993569   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "4           1.000000         0.000000  \n",
       "7           1.000000         0.000000  \n",
       "1           0.984491         0.008027  \n",
       "11          1.000000         0.000000  \n",
       "2           0.989013         0.002598  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "        'max_depth': [30, 60, 90, None]}\n",
    "\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(X_train_vect, y_train)\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time 0.111\n",
      "precision 0.575\n",
      "accuracy_score 0.575\n",
      "recall_score 0.575\n"
     ]
    }
   ],
   "source": [
    "print('Fit time',round(pred_time,3))\n",
    "print('precision',round(precision_score(y_test, y_pred,average='macro'),3))\n",
    "print('accuracy_score',round(precision_score(y_test, y_pred,average='macro'),3))    \n",
    "print('recall_score',round(precision_score(y_test, y_pred,average='macro'),3))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=60, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time 0.111\n",
      "precision 0.576\n",
      "accuracy_score 0.576\n",
      "recall_score 0.576\n"
     ]
    }
   ],
   "source": [
    "rf_model = gs_fit.best_estimator_.fit(X_train_vect, y_train)\n",
    "y_pred   = rf_model.predict(X_test_vect)\n",
    "\n",
    "print('Fit time',round(pred_time,3))\n",
    "print('precision',round(precision_score(y_test, y_pred,average='macro'),3))\n",
    "print('accuracy_score',round(precision_score(y_test, y_pred,average='macro'),3))    \n",
    "print('recall_score',round(precision_score(y_test, y_pred,average='macro'),3))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55128205, 0.46153846, 0.36363636, 0.58441558, 0.38961039])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = gs_fit.best_estimator_\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf, X_train_vect, y_train, cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_fit.best_estimator_.predict(X_test_vect)== y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=150, max_depth=11)\n",
    "\n",
    "start = time.time()\n",
    "gb_model = gb.fit(X_train_vect, y_train)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "start = time.time()\n",
    "y_pred = gb_model.predict(X_test_vect)\n",
    "end = time.time()\n",
    "pred_time = (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time 0.006\n",
      "precision 0.445\n",
      "accuracy_score 0.445\n",
      "recall_score 0.445\n"
     ]
    }
   ],
   "source": [
    "print('Fit time',round(pred_time,3))\n",
    "print('precision',round(precision_score(y_test, y_pred,average='macro'),3))\n",
    "print('accuracy_score',round(precision_score(y_test, y_pred,average='macro'),3))    \n",
    "print('recall_score',round(precision_score(y_test, y_pred,average='macro'),3))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.333291</td>\n",
       "      <td>0.465669</td>\n",
       "      <td>0.007798</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': ...</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475452</td>\n",
       "      <td>0.060715</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.644997</td>\n",
       "      <td>0.251446</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': ...</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470284</td>\n",
       "      <td>0.069543</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.474536</td>\n",
       "      <td>0.627462</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': ...</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470284</td>\n",
       "      <td>0.048567</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26.465589</td>\n",
       "      <td>0.659167</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': ...</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467700</td>\n",
       "      <td>0.055125</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.385452</td>\n",
       "      <td>0.409251</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': ...</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459948</td>\n",
       "      <td>0.061670</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "2      17.333291      0.465669         0.007798        0.000777   \n",
       "1      11.644997      0.251446         0.006582        0.000489   \n",
       "4      18.474536      0.627462         0.007579        0.000489   \n",
       "5      26.465589      0.659167         0.009375        0.000798   \n",
       "3       9.385452      0.409251         0.006384        0.000489   \n",
       "\n",
       "  param_learning_rate param_max_depth param_n_estimators  \\\n",
       "2                 0.1               7                150   \n",
       "1                 0.1               7                100   \n",
       "4                 0.1              11                100   \n",
       "5                 0.1              11                150   \n",
       "3                 0.1              11                 50   \n",
       "\n",
       "                                    params  split0_test_score  \\\n",
       "2  {'learning_rate': 0.1, 'max_depth': ...           0.544304   \n",
       "1  {'learning_rate': 0.1, 'max_depth': ...           0.518987   \n",
       "4  {'learning_rate': 0.1, 'max_depth': ...           0.531646   \n",
       "5  {'learning_rate': 0.1, 'max_depth': ...           0.493671   \n",
       "3  {'learning_rate': 0.1, 'max_depth': ...           0.544304   \n",
       "\n",
       "   split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "2           0.461538  ...         0.475452        0.060715                1   \n",
       "1           0.512821  ...         0.470284        0.069543                2   \n",
       "4           0.487179  ...         0.470284        0.048567                2   \n",
       "5           0.525641  ...         0.467700        0.055125                4   \n",
       "3           0.474359  ...         0.459948        0.061670                5   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "2                 1.0                 1.0                 1.0   \n",
       "1                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "5                 1.0                 1.0                 1.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "2                 1.0                 1.0               1.0              0.0  \n",
       "1                 1.0                 1.0               1.0              0.0  \n",
       "4                 1.0                 1.0               1.0              0.0  \n",
       "5                 1.0                 1.0               1.0              0.0  \n",
       "3                 1.0                 1.0               1.0              0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [50, 100, 150], \n",
    "    'max_depth': [7, 11, 15],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(gb, param, cv=5, n_jobs=-1)\n",
    "cv_fit = clf.fit(X_train_vect, y_train)\n",
    "pd.DataFrame(cv_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=7,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=150,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time 0.006\n",
      "precision 0.518\n",
      "accuracy_score 0.518\n",
      "recall_score 0.518\n"
     ]
    }
   ],
   "source": [
    "y_pred =  cv_fit.best_estimator_.predict(X_test_vect)\n",
    "\n",
    "print('Fit time',round(pred_time,3))\n",
    "print('precision',round(precision_score(y_test, y_pred,average='macro'),3))\n",
    "print('accuracy_score',round(precision_score(y_test, y_pred,average='macro'),3))    \n",
    "print('recall_score',round(precision_score(y_test, y_pred,average='macro'),3))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
